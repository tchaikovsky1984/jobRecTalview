import uuid
import os
from jobspy import scrape_jobs
from typing import List, Dict, Any
from temporalio import activity

from utils.datamodels import JobSearchCriteria

@activity.defn
def scraper(job_search_criteria: JobSearchCriteria) -> str: 
    print("============ACTIVITY STARTED================")
    jobtitle = job_search_criteria.title
    pref_country = job_search_criteria.pref_country
    pref_area = job_search_criteria.pref_area
    no_of_output = job_search_criteria.num
    print(job_search_criteria)
    if jobtitle==None:
        if pref_country==None:
            if pref_area==None:
                print("No options")
                jobs = scrape_jobs(
                        site_name=["indeed", "linkedin", "zip_recruiter", "glassdoor", "google"],
                        results_wanted=no_of_output,
                        hours_old=72,
                        )
            else:
                print("Only pref area")
                jobs = scrape_jobs(
                        site_name=["indeed", "linkedin", "zip_recruiter", "glassdoor", "google"],
                        results_wanted=no_of_output,
                        hours_old=72,
                        location=pref_area
                        )
        else:
            if pref_area==None:
                print("Only pref country")
                jobs = scrape_jobs(
                        site_name=["indeed", "linkedin", "zip_recruiter", "glassdoor", "google"],
                        results_wanted=no_of_output,
                        hours_old=72,
                        country_indeed=pref_country
                        )
            else:
                print("pref country and pref area")
                jobs = scrape_jobs(
                        site_name=["indeed", "linkedin", "zip_recruiter", "glassdoor", "google"],
                        results_wanted=no_of_output,
                        hours_old=72,
                        country_indeed=pref_country,
                        location=pref_area
                        )
    else:
        if pref_country==None:
            if pref_area==None:
                print("Only job title")
                jobs = scrape_jobs(
                        site_name=["indeed", "linkedin", "zip_recruiter", "glassdoor", "google"],
                        search_term=jobtitle,
                        google_search_term=jobtitle,
                        results_wanted=no_of_output,
                        hours_old=72,
                        )
            else:
                print("job title and pref_area")
                jobs = scrape_jobs(
                        site_name=["indeed", "linkedin", "zip_recruiter", "glassdoor", "google"],
                        search_term=jobtitle,
                        google_search_term=jobtitle,
                        results_wanted=no_of_output,
                        hours_old=72,
                        location=pref_area
                        )
        else:
            if pref_area==None:
                print("job title pref country and pref_area")
                jobs = scrape_jobs(
                        site_name=["indeed", "linkedin", "zip_recruiter", "glassdoor", "google"],
                        search_term=jobtitle,
                        google_search_term=jobtitle,
                        results_wanted=no_of_output,
                        hours_old=72,
                        country_indeed=pref_country
                        )
            else:
                print("job title and pref country") 
                jobs = scrape_jobs(
                        site_name=["indeed", "linkedin", "zip_recruiter", "glassdoor", "google"],
                        search_term=jobtitle,
                        google_search_term=jobtitle,
                        results_wanted=no_of_output,
                        hours_old=72,
                        country_indeed=pref_country,
                        location=pref_area,
                        )
    print("finished scraping")
    if not jobs.empty:
        STORAGE_DIR = "~/dev/jobRecTalview/samples/jobs/"
        jobs = jobs.drop('date_posted', axis=1)
        activity.logger.info(type(jobs.columns))

        file_name = f"jobs_{uuid.uuid4()}.csv"
        file_path = os.path.join(STORAGE_DIR, file_name)
        jobs.to_csv(file_path, index=False)

        print(f"DEBUG: Scraped {len(jobs)} jobs. Returning now.", flush=True)
        activity.logger.info(f"Scraped and converted {len(jobs)} jobs from a Dataframe to csv")
        return file_path
    else:
        print("DEBUG: Scraper returned empty.", flush=True)
        activity.logger.info("Scraper returned empty. Returning an empty list")
        return "NO_DATA"


